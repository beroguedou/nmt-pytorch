{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from models import *\n",
    "from attention import *\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== THE DATASET IS READY ========\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "get_file()\n",
    "path_to_file = 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of line in the dataset is 118964\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 118960\n",
    "_, target_tensor, _, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "#offset\n",
    "offset_target_tensor = np.zeros(target_tensor.shape)\n",
    "offset_target_tensor[:, :-1] = np.concatenate((target_tensor[:, 0:1], target_tensor[:, 2:]), axis=1)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ = max_length(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107064 107064 11896 11896\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(target_tensor, offset_target_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "4536 ----> camels\n",
      "21 ----> have\n",
      "766 ----> either\n",
      "73 ----> one\n",
      "183 ----> or\n",
      "143 ----> two\n",
      "10242 ----> humps\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "21 ----> have\n",
      "766 ----> either\n",
      "73 ----> one\n",
      "183 ----> or\n",
      "143 ----> two\n",
      "10242 ----> humps\n",
      "4 ----> .\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(targ_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)// BATCH_SIZE\n",
    "embedding_dim_source = 100\n",
    "embedding_dim_target = 100\n",
    "units = 1024\n",
    "vocab_inp_size = len(targ_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "CPU times: user 13.6 s, sys: 227 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "glove_dir = '../glove_weights/'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(glove_dir, 'glove.6B.100d.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_tar_size, embedding_dim))\n",
    "for word, i in targ_lang.word_index.items():\n",
    "    if i < vocab_tar_size:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x = torch.Tensor(input_tensor_train).long() \n",
    "tensor_y = torch.Tensor(target_tensor_train).long()\n",
    "# create your datset\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) \n",
    "# create your dataloader\n",
    "my_dataloader = data.DataLoader(my_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(my_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 42])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) torch.Size([64, 42, 1024])\n",
      "Encoder Hidden state shape: (batch size, units) torch.Size([1, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim_source, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) torch.Size([64, 1024])\n",
      "Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 42, 1])\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10, 1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) torch.Size([64, 13853])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim_target, units, BATCH_SIZE, 1024)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(torch.randint(1, 20, (BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim_source, units, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim_target, units, BATCH_SIZE, 1024).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the pretrained glove's weights in the Encoder and the Decoder\n",
    "encoder.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, device=device).float())\n",
    "# Setting the pretrained glove's weights in the Decoder\n",
    "decoder.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, device=device).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.3062\n",
      "Epoch 1 Batch 100 Loss 1.1429\n",
      "Epoch 1 Batch 200 Loss 1.1674\n",
      "Epoch 1 Batch 300 Loss 0.9613\n",
      "Epoch 1 Batch 400 Loss 1.2793\n",
      "Epoch 1 Batch 500 Loss 1.1812\n",
      "Epoch 1 Batch 600 Loss 0.9752\n",
      "Epoch 1 Batch 700 Loss 0.9952\n",
      "Epoch 1 Batch 800 Loss 1.2791\n",
      "Epoch 1 Batch 900 Loss 1.0729\n",
      "Epoch 1 Batch 1000 Loss 0.9917\n",
      "Epoch 1 Batch 1100 Loss 1.9817\n",
      "Epoch 1 Batch 1200 Loss 0.7582\n",
      "Epoch 1 Batch 1300 Loss 0.9618\n",
      "Epoch 1 Batch 1400 Loss 0.7487\n",
      "Epoch 1 Batch 1500 Loss 0.9973\n",
      "Epoch 1 Batch 1600 Loss 0.6855\n",
      "Epoch 1 Loss 1.0315\n",
      "Time taken for 1 epoch 1061.7810945510864 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.5665\n",
      "Epoch 2 Batch 100 Loss 0.3518\n",
      "Epoch 2 Batch 200 Loss 0.3223\n",
      "Epoch 2 Batch 300 Loss 0.2080\n",
      "Epoch 2 Batch 400 Loss 0.1757\n",
      "Epoch 2 Batch 500 Loss 0.1690\n",
      "Epoch 2 Batch 600 Loss 0.1541\n",
      "Epoch 2 Batch 700 Loss 0.1799\n",
      "Epoch 2 Batch 800 Loss 0.1702\n",
      "Epoch 2 Batch 900 Loss 0.0930\n",
      "Epoch 2 Batch 1000 Loss 0.1008\n",
      "Epoch 2 Batch 1100 Loss 0.0853\n",
      "Epoch 2 Batch 1200 Loss 0.1106\n",
      "Epoch 2 Batch 1300 Loss 0.1048\n",
      "Epoch 2 Batch 1400 Loss 0.0952\n",
      "Epoch 2 Batch 1500 Loss 0.1277\n",
      "Epoch 2 Batch 1600 Loss 0.0566\n",
      "Epoch 2 Loss 0.1808\n",
      "Time taken for 1 epoch 1062.1613073349 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0935\n",
      "Epoch 3 Batch 100 Loss 0.0653\n",
      "Epoch 3 Batch 200 Loss 0.0409\n",
      "Epoch 3 Batch 300 Loss 0.0626\n",
      "Epoch 3 Batch 400 Loss 0.0291\n",
      "Epoch 3 Batch 500 Loss 0.0423\n",
      "Epoch 3 Batch 600 Loss 0.0670\n",
      "Epoch 3 Batch 700 Loss 0.0809\n",
      "Epoch 3 Batch 800 Loss 0.0976\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 24\n",
    "PATH = \"decoder.pth\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(my_dataloader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        batch_loss = train_step(inp, targ, encoder, decoder,\n",
    "                                encoder_optimizer, decoder_optimizer,\n",
    "                                criterion, device, BATCH_SIZE, targ_lang)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        torch.save(decoder, PATH)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=10, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
