{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from models import *\n",
    "from attention import *\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== THE DATASET IS READY ========\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "get_file()\n",
    "path_to_file = 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of line in the dataset is 118964\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 118960\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107064 107064 11896 11896\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp_lang.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "15 ----> es\n",
      "11 ----> la\n",
      "820 ----> voz\n",
      "6 ----> de\n",
      "23 ----> una\n",
      "2009 ----> anciana\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "15 ----> it\n",
      "16 ----> s\n",
      "6 ----> the\n",
      "924 ----> voice\n",
      "19 ----> of\n",
      "74 ----> an\n",
      "154 ----> old\n",
      "426 ----> woman\n",
      "4 ----> .\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)// BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x = torch.Tensor(input_tensor_train).long() \n",
    "tensor_y = torch.Tensor(target_tensor_train).long()\n",
    "# create your datset\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) \n",
    "# create your dataloader\n",
    "my_dataloader = data.DataLoader(my_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(my_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 42])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) torch.Size([64, 42, 1024])\n",
      "Encoder Hidden state shape: (batch size, units) torch.Size([1, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) torch.Size([64, 1024])\n",
      "Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 42, 1])\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10, 1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) torch.Size([64, 12930])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(torch.randint(1, 20, (BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.2308\n",
      "Epoch 1 Batch 100 Loss 1.3001\n",
      "Epoch 1 Batch 200 Loss 0.9794\n",
      "Epoch 1 Batch 300 Loss 1.2874\n",
      "Epoch 1 Batch 400 Loss 0.9178\n",
      "Epoch 1 Batch 500 Loss 1.3672\n",
      "Epoch 1 Batch 600 Loss 0.7364\n",
      "Epoch 1 Batch 700 Loss 1.5136\n",
      "Epoch 1 Batch 800 Loss 0.7674\n",
      "Epoch 1 Batch 900 Loss 1.3587\n",
      "Epoch 1 Batch 1000 Loss 0.6570\n",
      "Epoch 1 Batch 1100 Loss 0.7186\n",
      "Epoch 1 Batch 1200 Loss 0.6857\n",
      "Epoch 1 Batch 1300 Loss 0.7897\n",
      "Epoch 1 Batch 1400 Loss 0.7597\n",
      "Epoch 1 Batch 1500 Loss 0.5298\n",
      "Epoch 1 Batch 1600 Loss 0.9037\n",
      "Epoch 1 Loss 0.9999\n",
      "Time taken for 1 epoch 1102.848022222519 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.7875\n",
      "Epoch 2 Batch 100 Loss 0.7621\n",
      "Epoch 2 Batch 200 Loss 0.5236\n",
      "Epoch 2 Batch 300 Loss 0.6147\n",
      "Epoch 2 Batch 400 Loss 0.5021\n",
      "Epoch 2 Batch 500 Loss 0.4828\n",
      "Epoch 2 Batch 600 Loss 0.7860\n",
      "Epoch 2 Batch 700 Loss 0.6613\n",
      "Epoch 2 Batch 800 Loss 0.9216\n",
      "Epoch 2 Batch 900 Loss 1.0046\n",
      "Epoch 2 Batch 1000 Loss 0.7857\n",
      "Epoch 2 Batch 1100 Loss 0.7995\n",
      "Epoch 2 Batch 1200 Loss 0.6462\n",
      "Epoch 2 Batch 1300 Loss 0.5012\n",
      "Epoch 2 Batch 1400 Loss 0.4647\n",
      "Epoch 2 Batch 1500 Loss 0.4793\n",
      "Epoch 2 Batch 1600 Loss 0.3865\n",
      "Epoch 2 Loss 0.6279\n",
      "Time taken for 1 epoch 1098.8398895263672 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6840\n",
      "Epoch 3 Batch 100 Loss 0.3706\n",
      "Epoch 3 Batch 200 Loss 0.4246\n",
      "Epoch 3 Batch 300 Loss 0.5898\n",
      "Epoch 3 Batch 400 Loss 0.3402\n",
      "Epoch 3 Batch 500 Loss 0.6930\n",
      "Epoch 3 Batch 600 Loss 0.3668\n",
      "Epoch 3 Batch 700 Loss 0.5771\n",
      "Epoch 3 Batch 800 Loss 0.4919\n",
      "Epoch 3 Batch 900 Loss 0.4497\n",
      "Epoch 3 Batch 1000 Loss 0.2809\n",
      "Epoch 3 Batch 1100 Loss 0.4762\n",
      "Epoch 3 Batch 1200 Loss 0.3436\n",
      "Epoch 3 Batch 1300 Loss 0.5785\n",
      "Epoch 3 Batch 1400 Loss 0.5560\n",
      "Epoch 3 Batch 1500 Loss 0.3935\n",
      "Epoch 3 Batch 1600 Loss 0.2924\n",
      "Epoch 3 Loss 0.5131\n",
      "Time taken for 1 epoch 1098.4352910518646 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5346\n",
      "Epoch 4 Batch 100 Loss 0.3012\n",
      "Epoch 4 Batch 200 Loss 0.3356\n",
      "Epoch 4 Batch 300 Loss 0.4059\n",
      "Epoch 4 Batch 400 Loss 0.3313\n",
      "Epoch 4 Batch 500 Loss 0.4773\n",
      "Epoch 4 Batch 600 Loss 0.2529\n",
      "Epoch 4 Batch 700 Loss 0.4952\n",
      "Epoch 4 Batch 800 Loss 0.4102\n",
      "Epoch 4 Batch 900 Loss 0.4260\n",
      "Epoch 4 Batch 1000 Loss 0.4537\n",
      "Epoch 4 Batch 1100 Loss 0.2658\n",
      "Epoch 4 Batch 1200 Loss 0.4911\n",
      "Epoch 4 Batch 1300 Loss 0.5682\n",
      "Epoch 4 Batch 1400 Loss 0.3386\n",
      "Epoch 4 Batch 1500 Loss 0.4945\n",
      "Epoch 4 Batch 1600 Loss 0.5546\n",
      "Epoch 4 Loss 0.4086\n",
      "Time taken for 1 epoch 1098.2742421627045 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4114\n",
      "Epoch 5 Batch 100 Loss 0.2325\n",
      "Epoch 5 Batch 200 Loss 0.4766\n",
      "Epoch 5 Batch 300 Loss 0.2558\n",
      "Epoch 5 Batch 400 Loss 0.2595\n",
      "Epoch 5 Batch 500 Loss 0.4140\n",
      "Epoch 5 Batch 600 Loss 0.3168\n",
      "Epoch 5 Batch 700 Loss 0.5647\n",
      "Epoch 5 Batch 800 Loss 0.2894\n",
      "Epoch 5 Batch 900 Loss 0.3972\n",
      "Epoch 5 Batch 1000 Loss 0.3728\n",
      "Epoch 5 Batch 1100 Loss 0.4298\n",
      "Epoch 5 Batch 1200 Loss 0.4903\n",
      "Epoch 5 Batch 1300 Loss 0.2407\n",
      "Epoch 5 Batch 1400 Loss 0.2938\n",
      "Epoch 5 Batch 1500 Loss 0.2422\n",
      "Epoch 5 Batch 1600 Loss 0.2448\n",
      "Epoch 5 Loss 0.3535\n",
      "Time taken for 1 epoch 1098.1027674674988 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2178\n",
      "Epoch 6 Batch 100 Loss 0.2186\n",
      "Epoch 6 Batch 200 Loss 0.2211\n",
      "Epoch 6 Batch 300 Loss 0.3118\n",
      "Epoch 6 Batch 400 Loss 0.1801\n",
      "Epoch 6 Batch 500 Loss 0.4210\n",
      "Epoch 6 Batch 600 Loss 0.2146\n",
      "Epoch 6 Batch 700 Loss 0.4725\n",
      "Epoch 6 Batch 800 Loss 0.3700\n",
      "Epoch 6 Batch 900 Loss 0.2339\n",
      "Epoch 6 Batch 1000 Loss 0.1610\n",
      "Epoch 6 Batch 1100 Loss 0.2202\n",
      "Epoch 6 Batch 1200 Loss 0.1832\n",
      "Epoch 6 Batch 1300 Loss 0.2235\n",
      "Epoch 6 Batch 1400 Loss 0.2033\n",
      "Epoch 6 Batch 1500 Loss 0.2353\n",
      "Epoch 6 Batch 1600 Loss 0.2657\n",
      "Epoch 6 Loss 0.3116\n",
      "Time taken for 1 epoch 1097.8487465381622 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3031\n",
      "Epoch 7 Batch 100 Loss 0.3386\n",
      "Epoch 7 Batch 200 Loss 0.1915\n",
      "Epoch 7 Batch 300 Loss 0.1748\n",
      "Epoch 7 Batch 400 Loss 0.3126\n",
      "Epoch 7 Batch 500 Loss 0.3340\n",
      "Epoch 7 Batch 600 Loss 0.1856\n",
      "Epoch 7 Batch 700 Loss 0.2526\n",
      "Epoch 7 Batch 800 Loss 0.3782\n",
      "Epoch 7 Batch 900 Loss 0.1569\n",
      "Epoch 7 Batch 1000 Loss 0.3595\n",
      "Epoch 7 Batch 1100 Loss 0.4936\n",
      "Epoch 7 Batch 1200 Loss 0.2541\n",
      "Epoch 7 Batch 1300 Loss 0.2025\n",
      "Epoch 7 Batch 1400 Loss 0.3976\n",
      "Epoch 7 Batch 1500 Loss 0.1370\n",
      "Epoch 7 Batch 1600 Loss 0.3552\n",
      "Epoch 7 Loss 0.2805\n",
      "Time taken for 1 epoch 1097.6744916439056 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1718\n",
      "Epoch 8 Batch 100 Loss 0.2627\n",
      "Epoch 8 Batch 200 Loss 0.2874\n",
      "Epoch 8 Batch 300 Loss 0.3486\n",
      "Epoch 8 Batch 400 Loss 0.2293\n",
      "Epoch 8 Batch 500 Loss 0.2037\n",
      "Epoch 8 Batch 600 Loss 0.3734\n",
      "Epoch 8 Batch 700 Loss 0.2834\n",
      "Epoch 8 Batch 800 Loss 0.3346\n",
      "Epoch 8 Batch 900 Loss 0.2207\n",
      "Epoch 8 Batch 1000 Loss 0.1604\n",
      "Epoch 8 Batch 1100 Loss 0.3169\n",
      "Epoch 8 Batch 1200 Loss 0.3386\n",
      "Epoch 8 Batch 1300 Loss 0.1799\n",
      "Epoch 8 Batch 1400 Loss 0.2102\n",
      "Epoch 8 Batch 1500 Loss 0.1739\n",
      "Epoch 8 Batch 1600 Loss 0.3435\n",
      "Epoch 8 Loss 0.2570\n",
      "Time taken for 1 epoch 1097.51588845253 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1671\n",
      "Epoch 9 Batch 100 Loss 0.1069\n",
      "Epoch 9 Batch 200 Loss 0.2250\n",
      "Epoch 9 Batch 300 Loss 0.1390\n",
      "Epoch 9 Batch 400 Loss 0.2898\n",
      "Epoch 9 Batch 500 Loss 0.1477\n",
      "Epoch 9 Batch 600 Loss 0.3305\n",
      "Epoch 9 Batch 700 Loss 0.2949\n",
      "Epoch 9 Batch 800 Loss 0.1692\n",
      "Epoch 9 Batch 900 Loss 0.3340\n",
      "Epoch 9 Batch 1000 Loss 0.3830\n",
      "Epoch 9 Batch 1100 Loss 0.3937\n",
      "Epoch 9 Batch 1200 Loss 0.3475\n",
      "Epoch 9 Batch 1300 Loss 0.2727\n",
      "Epoch 9 Batch 1400 Loss 0.3618\n",
      "Epoch 9 Batch 1500 Loss 0.3845\n",
      "Epoch 9 Batch 1600 Loss 0.3042\n",
      "Epoch 9 Loss 0.2422\n",
      "Time taken for 1 epoch 1097.6020123958588 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2913\n",
      "Epoch 10 Batch 100 Loss 0.0926\n",
      "Epoch 10 Batch 200 Loss 0.2561\n",
      "Epoch 10 Batch 300 Loss 0.1356\n",
      "Epoch 10 Batch 400 Loss 0.1453\n",
      "Epoch 10 Batch 500 Loss 0.4365\n",
      "Epoch 10 Batch 600 Loss 0.3006\n",
      "Epoch 10 Batch 700 Loss 0.2897\n",
      "Epoch 10 Batch 800 Loss 0.1713\n",
      "Epoch 10 Batch 900 Loss 0.4027\n",
      "Epoch 10 Batch 1000 Loss 0.1836\n",
      "Epoch 10 Batch 1100 Loss 0.2753\n",
      "Epoch 10 Batch 1200 Loss 0.1377\n",
      "Epoch 10 Batch 1300 Loss 0.3442\n",
      "Epoch 10 Batch 1400 Loss 0.1875\n",
      "Epoch 10 Batch 1500 Loss 0.1465\n",
      "Epoch 10 Batch 1600 Loss 0.3522\n",
      "Epoch 10 Loss 0.2364\n",
      "Time taken for 1 epoch 1097.5258417129517 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(my_dataloader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        batch_loss = train_step(inp, targ, encoder, decoder,\n",
    "                                encoder_optimizer, decoder_optimizer,\n",
    "                                criterion, device, BATCH_SIZE, targ_lang)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 260, 7, 440, 4, 3]\n",
      "====================\n",
      "[2, 260, 7, 440, 4, 3]\n",
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: <start> try to change . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=10, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to change . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: <start> are you home home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'¿ todavia estan en casa ?', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are you home home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'¿ todavia estan en casa ? ', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: <start> this is my life . \n"
     ]
    }
   ],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: <start> this is my life . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " c ici\n",
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it weather very cold here . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device, beam_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: <start> it weather very cold here . <end> \n",
      "CPU times: user 166 ms, sys: 11.8 ms, total: 178 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "translate(u'hace mucho frio aqui .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device, beam_width=3, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
