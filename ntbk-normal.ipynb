{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from models import *\n",
    "from attention import *\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== THE DATASET IS READY ========\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "get_file()\n",
    "path_to_file = 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of line in the dataset is 118964\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 118960\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107064 107064 11896 11896\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "7 ----> el\n",
      "15 ----> es\n",
      "10172 ----> futbolista\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "13 ----> he\n",
      "12 ----> is\n",
      "10 ----> a\n",
      "860 ----> soccer\n",
      "1137 ----> player\n",
      "4 ----> .\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)// BATCH_SIZE\n",
    "embedding_dim_source = 256\n",
    "embedding_dim_target = 100\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "CPU times: user 13.6 s, sys: 267 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "glove_dir = '../glove_weights/'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(glove_dir, 'glove.6B.100d.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_tar_size, embedding_dim))\n",
    "for word, i in targ_lang.word_index.items():\n",
    "    if i < vocab_tar_size:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x = torch.Tensor(input_tensor_train).long() \n",
    "tensor_y = torch.Tensor(target_tensor_train).long()\n",
    "# create your datset\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) \n",
    "# create your dataloader\n",
    "my_dataloader = data.DataLoader(my_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(my_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 42])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) torch.Size([64, 42, 1024])\n",
      "Encoder Hidden state shape: (batch size, units) torch.Size([1, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim_source, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) torch.Size([64, 1024])\n",
      "Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 42, 1])\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10, 1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) torch.Size([64, 13853])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim_target, units, BATCH_SIZE, 1024)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(torch.randint(1, 20, (BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim_source, units, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim_target, units, BATCH_SIZE, 1024).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the pretrained glove's weights in the Decoder\n",
    "decoder.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, device=device).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.3025\n",
      "Epoch 1 Batch 100 Loss 1.7025\n",
      "Epoch 1 Batch 200 Loss 1.5339\n",
      "Epoch 1 Batch 300 Loss 1.2020\n",
      "Epoch 1 Batch 400 Loss 1.0292\n",
      "Epoch 1 Batch 500 Loss 1.0688\n",
      "Epoch 1 Batch 600 Loss 1.2681\n",
      "Epoch 1 Batch 700 Loss 0.9368\n",
      "Epoch 1 Batch 800 Loss 1.2883\n",
      "Epoch 1 Batch 900 Loss 1.0381\n",
      "Epoch 1 Batch 1000 Loss 0.9625\n",
      "Epoch 1 Batch 1100 Loss 0.9252\n",
      "Epoch 1 Batch 1200 Loss 0.9168\n",
      "Epoch 1 Batch 1300 Loss 0.8842\n",
      "Epoch 1 Batch 1400 Loss 1.1590\n",
      "Epoch 1 Batch 1500 Loss 1.3492\n",
      "Epoch 1 Batch 1600 Loss 0.7430\n",
      "Epoch 1 Loss 1.2110\n",
      "Time taken for 1 epoch 1076.4737224578857 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.7252\n",
      "Epoch 2 Batch 100 Loss 1.5175\n",
      "Epoch 2 Batch 200 Loss 0.8572\n",
      "Epoch 2 Batch 300 Loss 0.7244\n",
      "Epoch 2 Batch 400 Loss 1.2360\n",
      "Epoch 2 Batch 500 Loss 0.7041\n",
      "Epoch 2 Batch 600 Loss 0.9075\n",
      "Epoch 2 Batch 700 Loss 0.7779\n",
      "Epoch 2 Batch 800 Loss 0.7562\n",
      "Epoch 2 Batch 900 Loss 0.8102\n",
      "Epoch 2 Batch 1000 Loss 0.5955\n",
      "Epoch 2 Batch 1100 Loss 0.6611\n",
      "Epoch 2 Batch 1200 Loss 0.9849\n",
      "Epoch 2 Batch 1300 Loss 0.7949\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(my_dataloader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        batch_loss = train_step(inp, targ, encoder, decoder,\n",
    "                                encoder_optimizer, decoder_optimizer,\n",
    "                                criterion, device, BATCH_SIZE, targ_lang)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=10, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=100, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder,\n",
    "          decoder, inp_lang, targ_lang, device, beam_width=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'hace mucho frio aqui .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device, beam_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "translate(u'hace mucho frio aqui .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device, beam_width=5, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
